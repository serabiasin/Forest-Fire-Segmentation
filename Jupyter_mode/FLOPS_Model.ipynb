{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rikPwivn7022"
      },
      "outputs": [],
      "source": [
        "!pip install -U fvcore\n",
        "!pip install -U git+https://github.com/qubvel/segmentation_models.pytorch\n",
        "!pip install pytorch-lightning\n",
        "!pip install albumentations\n",
        "!pip install torchvision       "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "# https://drive.google.com/file/d/1Vog0SCV90K3Z-3IRw-aVUqTKGSNaHEhx/view?usp=sharing\n",
        "\n",
        "url='https://drive.google.com/uc?id=1Vog0SCV90K3Z-3IRw-aVUqTKGSNaHEhx'\n",
        "output_file_train='resnet_unet.ckpt'\n",
        "\n",
        "gdown.download(url, output_file_train, quiet=False)\n",
        "\n",
        "# https://drive.google.com/file/d/1_1g7zTV0IPce8AN3SxcMaNL2j40otoLN/view?usp=sharing\n",
        "url='https://drive.google.com/uc?id=1_1g7zTV0IPce8AN3SxcMaNL2j40otoLN'\n",
        "output_file_train='mobilenetv2_nontune.ckpt'\n",
        "\n",
        "gdown.download(url, output_file_train, quiet=False)\n",
        "\n",
        "#https://drive.google.com/file/d/1LeicojNwoQM6-eLGdu1pX4EkKXB2D7RX/view?usp=sharing\n",
        "url='https://drive.google.com/uc?id=1LeicojNwoQM6-eLGdu1pX4EkKXB2D7RX'\n",
        "output_file_train='mix_transfomer_unet.ckpt'\n",
        "\n",
        "gdown.download(url, output_file_train, quiet=False)\n",
        "\n",
        "#https://drive.google.com/file/d/1irlDBPZWBqLTjrh-IgmQ0pgrwPAMRF76/view?usp=sharing\n",
        "url='https://drive.google.com/uc?id=1irlDBPZWBqLTjrh-IgmQ0pgrwPAMRF76'\n",
        "output_file_train='mix_transfomer_unet_b1.ckpt'\n",
        "\n",
        "gdown.download(url, output_file_train, quiet=False)"
      ],
      "metadata": {
        "id": "324NRUIO8CA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "class Segmentation_custom(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, arch, encoder_name, in_channels, out_classes, **kwargs):\n",
        "        super().__init__()\n",
        "        self.model = smp.create_model(\n",
        "            arch, encoder_name=encoder_name, in_channels=in_channels, classes=out_classes, **kwargs\n",
        "        )\n",
        "\n",
        "        # for image segmentation dice loss could be the best first choice\n",
        "        # self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)\n",
        "        self.loss_fn = smp.losses.DiceLoss(smp.losses.BINARY_MODE)\n",
        "\n",
        "    def forward(self, image):\n",
        "        # normalize image here\n",
        "        mask = self.model(image)\n",
        "        return mask\n",
        "\n",
        "    def shared_step(self, batch, stage):\n",
        "        \n",
        "        image = batch[\"image\"]\n",
        "\n",
        "        # Shape of the image should be (batch_size, num_channels, height, width)\n",
        "        # if you work with grayscale images, expand channels dim to have [batch_size, 1, height, width]\n",
        "        assert image.ndim == 4\n",
        "\n",
        "        # Check that image dimensions are divisible by 32, \n",
        "        # encoder and decoder connected by `skip connections` and usually encoder have 5 stages of \n",
        "        # downsampling by factor 2 (2 ^ 5 = 32); e.g. if we have image with shape 65x65 we will have \n",
        "        # following shapes of features in encoder and decoder: 84, 42, 21, 10, 5 -> 5, 10, 20, 40, 80\n",
        "        # and we will get an error trying to concat these features\n",
        "        h, w = image.shape[2:]\n",
        "        assert h % 32 == 0 and w % 32 == 0\n",
        "\n",
        "        mask = batch[\"mask\"]\n",
        "\n",
        "        # Shape of the mask should be [batch_size, num_classes, height, width]\n",
        "        # for binary segmentation num_classes = 1\n",
        "        assert mask.ndim == 4\n",
        "        \n",
        "\n",
        "        # Check that mask values in between 0 and 1, NOT 0 and 255 for binary segmentation\n",
        "        assert mask.max() <= 1.0 and mask.min() >= 0\n",
        "\n",
        "        logits_mask = self.forward(image)\n",
        "        \n",
        "        # Predicted mask contains logits, and loss_fn param `from_logits` is set to True\n",
        "        loss = self.loss_fn(logits_mask, mask)\n",
        "\n",
        "        # Lets compute metrics for some threshold\n",
        "        # first convert mask values to probabilities, then \n",
        "        # apply thresholding\n",
        "        prob_mask = logits_mask.sigmoid()\n",
        "        pred_mask = (prob_mask > 0.5).float()\n",
        "\n",
        "        # We will compute IoU metric by two ways\n",
        "        #   1. dataset-wise\n",
        "        #   2. image-wise\n",
        "        # but for now we just compute true positive, false positive, false negative and\n",
        "        # true negative 'pixels' for each image and class\n",
        "        # these values will be aggregated in the end of an epoch\n",
        "        tp, fp, fn, tn = smp.metrics.get_stats(pred_mask.long(), mask.long(), mode=\"binary\")\n",
        "\n",
        "        return {\n",
        "            \"loss\": loss,\n",
        "            \"tp\": tp,\n",
        "            \"fp\": fp,\n",
        "            \"fn\": fn,\n",
        "            \"tn\": tn,\n",
        "        }\n",
        "\n",
        "    def shared_epoch_end(self, outputs, stage):\n",
        "        # aggregate step metics\n",
        "        tp = torch.cat([x[\"tp\"] for x in outputs])\n",
        "        fp = torch.cat([x[\"fp\"] for x in outputs])\n",
        "        fn = torch.cat([x[\"fn\"] for x in outputs])\n",
        "        tn = torch.cat([x[\"tn\"] for x in outputs])\n",
        "\n",
        "        # per image IoU means that we first calculate IoU score for each image \n",
        "        # and then compute mean over these scores\n",
        "        per_image_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro-imagewise\")\n",
        "        \n",
        "        # dataset IoU means that we aggregate intersection and union over whole dataset\n",
        "        # and then compute IoU score. The difference between dataset_iou and per_image_iou scores\n",
        "        # in this particular case will not be much, however for dataset \n",
        "        # with \"empty\" images (images without target class) a large gap could be observed. \n",
        "        # Empty images influence a lot on per_image_iou and much less on dataset_iou.\n",
        "        dataset_iou = smp.metrics.iou_score(tp, fp, fn, tn, reduction=\"micro\")\n",
        "\n",
        "        metrics = {\n",
        "            f\"{stage}_per_image_iou\": per_image_iou,\n",
        "            f\"{stage}_dataset_iou\": dataset_iou,\n",
        "        }\n",
        "        \n",
        "        self.log_dict(metrics, prog_bar=True)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"train\")            \n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"train\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"valid\")\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"valid\")\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.shared_step(batch, \"test\")  \n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        return self.shared_epoch_end(outputs, \"test\")\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "3EnHkd528DoJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_mitb0 = Segmentation_custom.load_from_checkpoint('/content/mix_transfomer_unet.ckpt',arch=\"Unet\", encoder_name=\"mit_b0\", in_channels=3, out_classes=1)\n",
        "model_mitb1 = Segmentation_custom.load_from_checkpoint('/content/mix_transfomer_unet_b1.ckpt',arch=\"Unet\", encoder_name=\"mit_b1\", in_channels=3, out_classes=1)\n",
        "model_resnet50 = Segmentation_custom.load_from_checkpoint('/content/resnet_unet.ckpt',arch=\"Unet\", encoder_name=\"resnet50\", in_channels=3, out_classes=1)\n",
        "model_mobilenetv2 = Segmentation_custom.load_from_checkpoint('/content/mobilenetv2_nontune.ckpt',arch=\"Unet\", encoder_name=\"mobilenet_v2\", in_channels=3, out_classes=1)\n",
        "\n",
        "model_mitb0.cuda()\n",
        "model_mitb1.cuda()\n",
        "model_resnet50.cuda()\n",
        "model_mobilenetv2.cuda()"
      ],
      "metadata": {
        "id": "44mR-jk58FdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fvcore.nn import FlopCountAnalysis, flop_count_table, flop_count_str,ActivationCountAnalysis\n",
        "import torch\n",
        "\n",
        "input = torch.randn(1,3, 224, 224)\n",
        "input=input.type(torch.cuda.FloatTensor)\n",
        "\n",
        "input.cuda()\n",
        "\n",
        "flops_model_mitb0= FlopCountAnalysis(model_mitb0, input)\n",
        "flops_model_mitb1=FlopCountAnalysis(model_mitb1, input)\n",
        "flops_resnet50=FlopCountAnalysis(model_resnet50, input)\n",
        "flops_mobilenetv2=FlopCountAnalysis(model_mobilenetv2, input)\n"
      ],
      "metadata": {
        "id": "k6NGpp4q8ONw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(flop_count_table(flops_model_mitb0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lFHaCxr8beu",
        "outputId": "ca9ed3e8-1dc0-4dfe-81d2-ab1a716e6cd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| module                       | #parameters or shape   | #flops     |\n",
            "|:-----------------------------|:-----------------------|:-----------|\n",
            "| model                        | 5.549M                 | 2.29G      |\n",
            "|  encoder                     |  3.319M                |  0.458G    |\n",
            "|   encoder.patch_embed1       |   4.8K                 |   15.254M  |\n",
            "|    encoder.patch_embed1.proj |    4.736K              |    14.752M |\n",
            "|    encoder.patch_embed1.norm |    64                  |    0.502M  |\n",
            "|   encoder.patch_embed2       |   18.624K              |   14.702M  |\n",
            "|    encoder.patch_embed2.proj |    18.496K             |    14.451M |\n",
            "|    encoder.patch_embed2.norm |    0.128K              |    0.251M  |\n",
            "|   encoder.patch_embed3       |   92.64K               |   18.22M   |\n",
            "|    encoder.patch_embed3.proj |    92.32K              |    18.063M |\n",
            "|    encoder.patch_embed3.norm |    0.32K               |    0.157M  |\n",
            "|   encoder.patch_embed4       |   0.369M               |   18.126M  |\n",
            "|    encoder.patch_embed4.proj |    0.369M              |    18.063M |\n",
            "|    encoder.patch_embed4.norm |    0.512K              |    62.72K  |\n",
            "|   encoder.block1             |   0.159M               |   99.766M  |\n",
            "|    encoder.block1.0          |    79.616K             |    49.883M |\n",
            "|    encoder.block1.1          |    79.616K             |    49.883M |\n",
            "|   encoder.norm1              |   64                   |   0.502M   |\n",
            "|    encoder.norm1.weight      |    (32,)               |            |\n",
            "|    encoder.norm1.bias        |    (32,)               |            |\n",
            "|   encoder.block2             |   0.237M               |   85.933M  |\n",
            "|    encoder.block2.0          |    0.118M              |    42.966M |\n",
            "|    encoder.block2.1          |    0.118M              |    42.966M |\n",
            "|   encoder.norm2              |   0.128K               |   0.251M   |\n",
            "|    encoder.norm2.weight      |    (64,)               |            |\n",
            "|    encoder.norm2.bias        |    (64,)               |            |\n",
            "|   encoder.block3             |   0.837M               |   0.125G   |\n",
            "|    encoder.block3.0          |    0.419M              |    62.257M |\n",
            "|    encoder.block3.1          |    0.419M              |    62.257M |\n",
            "|   encoder.norm3              |   0.32K                |   0.157M   |\n",
            "|    encoder.norm3.weight      |    (160,)              |            |\n",
            "|    encoder.norm3.bias        |    (160,)              |            |\n",
            "|   encoder.block4             |   1.6M                 |   80.683M  |\n",
            "|    encoder.block4.0          |    0.8M                |    40.342M |\n",
            "|    encoder.block4.1          |    0.8M                |    40.342M |\n",
            "|   encoder.norm4              |   0.512K               |   62.72K   |\n",
            "|    encoder.norm4.weight      |    (256,)              |            |\n",
            "|    encoder.norm4.bias        |    (256,)              |            |\n",
            "|  decoder.blocks              |  2.23M                 |  1.825G    |\n",
            "|   decoder.blocks.0           |   1.549M               |   0.304G   |\n",
            "|    decoder.blocks.0.conv1    |    0.959M              |    0.188G  |\n",
            "|    decoder.blocks.0.conv2    |    0.59M               |    0.116G  |\n",
            "|   decoder.blocks.1           |   0.517M               |   0.406G   |\n",
            "|    decoder.blocks.1.conv1    |    0.369M              |    0.29G   |\n",
            "|    decoder.blocks.1.conv2    |    0.148M              |    0.116G  |\n",
            "|   decoder.blocks.2           |   0.129M               |   0.407G   |\n",
            "|    decoder.blocks.2.conv1    |    92.288K             |    0.29G   |\n",
            "|    decoder.blocks.2.conv2    |    36.992K             |    0.117G  |\n",
            "|   decoder.blocks.3           |   27.776K              |   0.352G   |\n",
            "|    decoder.blocks.3.conv1    |    18.496K             |    0.233G  |\n",
            "|    decoder.blocks.3.conv2    |    9.28K               |    0.118G  |\n",
            "|   decoder.blocks.4           |   6.976K               |   0.356G   |\n",
            "|    decoder.blocks.4.conv1    |    4.64K               |    0.235G  |\n",
            "|    decoder.blocks.4.conv2    |    2.336K              |    0.12G   |\n",
            "|  segmentation_head.0         |  0.145K                |  7.225M    |\n",
            "|   segmentation_head.0.weight |   (1, 16, 3, 3)        |            |\n",
            "|   segmentation_head.0.bias   |   (1,)                 |            |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(flop_count_table(flops_model_mitb1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ_iFM3u8bvh",
        "outputId": "612e0531-d685-41bb-f9a8-7631613cf623"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| module                       | #parameters or shape   | #flops     |\n",
            "|:-----------------------------|:-----------------------|:-----------|\n",
            "| model                        | 16.432M                | 3.823G     |\n",
            "|  encoder                     |  13.151M               |  1.687G    |\n",
            "|   encoder.patch_embed1       |   9.6K                 |   30.507M  |\n",
            "|    encoder.patch_embed1.proj |    9.472K              |    29.503M |\n",
            "|    encoder.patch_embed1.norm |    0.128K              |    1.004M  |\n",
            "|   encoder.patch_embed2       |   74.112K              |   58.305M  |\n",
            "|    encoder.patch_embed2.proj |    73.856K             |    57.803M |\n",
            "|    encoder.patch_embed2.norm |    0.256K              |    0.502M  |\n",
            "|   encoder.patch_embed3       |   0.37M                |   72.567M  |\n",
            "|    encoder.patch_embed3.proj |    0.369M              |    72.253M |\n",
            "|    encoder.patch_embed3.norm |    0.64K               |    0.314M  |\n",
            "|   encoder.patch_embed4       |   1.476M               |   72.379M  |\n",
            "|    encoder.patch_embed4.proj |    1.475M              |    72.253M |\n",
            "|    encoder.patch_embed4.norm |    1.024K              |    0.125M  |\n",
            "|   encoder.block1             |   0.63M                |   0.341G   |\n",
            "|    encoder.block1.0          |    0.315M              |    0.171G  |\n",
            "|    encoder.block1.1          |    0.315M              |    0.171G  |\n",
            "|   encoder.norm1              |   0.128K               |   1.004M   |\n",
            "|    encoder.norm1.weight      |    (64,)               |            |\n",
            "|    encoder.norm1.bias        |    (64,)               |            |\n",
            "|   encoder.block2             |   0.932M               |   0.315G   |\n",
            "|    encoder.block2.0          |    0.466M              |    0.157G  |\n",
            "|    encoder.block2.1          |    0.466M              |    0.157G  |\n",
            "|   encoder.norm2              |   0.256K               |   0.502M   |\n",
            "|    encoder.norm2.weight      |    (128,)              |            |\n",
            "|    encoder.norm2.bias        |    (128,)              |            |\n",
            "|   encoder.block3             |   3.313M               |   0.48G    |\n",
            "|    encoder.block3.0          |    1.656M              |    0.24G   |\n",
            "|    encoder.block3.1          |    1.656M              |    0.24G   |\n",
            "|   encoder.norm3              |   0.64K                |   0.314M   |\n",
            "|    encoder.norm3.weight      |    (320,)              |            |\n",
            "|    encoder.norm3.bias        |    (320,)              |            |\n",
            "|   encoder.block4             |   6.346M               |   0.316G   |\n",
            "|    encoder.block4.0          |    3.173M              |    0.158G  |\n",
            "|    encoder.block4.1          |    3.173M              |    0.158G  |\n",
            "|   encoder.norm4              |   1.024K               |   0.125M   |\n",
            "|    encoder.norm4.weight      |    (512,)              |            |\n",
            "|    encoder.norm4.bias        |    (512,)              |            |\n",
            "|  decoder.blocks              |  3.281M                |  2.128G    |\n",
            "|   decoder.blocks.0           |   2.508M               |   0.492G   |\n",
            "|    decoder.blocks.0.conv1    |    1.917M              |    0.376G  |\n",
            "|    decoder.blocks.0.conv2    |    0.59M               |    0.116G  |\n",
            "|   decoder.blocks.1           |   0.59M                |   0.464G   |\n",
            "|    decoder.blocks.1.conv1    |    0.443M              |    0.347G  |\n",
            "|    decoder.blocks.1.conv2    |    0.148M              |    0.116G  |\n",
            "|   decoder.blocks.2           |   0.148M               |   0.465G   |\n",
            "|    decoder.blocks.2.conv1    |    0.111M              |    0.348G  |\n",
            "|    decoder.blocks.2.conv2    |    36.992K             |    0.117G  |\n",
            "|   decoder.blocks.3           |   27.776K              |   0.352G   |\n",
            "|    decoder.blocks.3.conv1    |    18.496K             |    0.233G  |\n",
            "|    decoder.blocks.3.conv2    |    9.28K               |    0.118G  |\n",
            "|   decoder.blocks.4           |   6.976K               |   0.356G   |\n",
            "|    decoder.blocks.4.conv1    |    4.64K               |    0.235G  |\n",
            "|    decoder.blocks.4.conv2    |    2.336K              |    0.12G   |\n",
            "|  segmentation_head.0         |  0.145K                |  7.225M    |\n",
            "|   segmentation_head.0.weight |   (1, 16, 3, 3)        |            |\n",
            "|   segmentation_head.0.bias   |   (1,)                 |            |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(flop_count_table(flops_resnet50))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H05YgygY8b80",
        "outputId": "120cfe13-4f4b-474c-b896-855dfa60c81f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| module                       | #parameters or shape   | #flops    |\n",
            "|:-----------------------------|:-----------------------|:----------|\n",
            "| model                        | 32.521M                | 8.215G    |\n",
            "|  encoder                     |  23.508M               |  4.143G   |\n",
            "|   encoder.conv1              |   9.408K               |   0.118G  |\n",
            "|    encoder.conv1.weight      |    (64, 3, 7, 7)       |           |\n",
            "|   encoder.bn1                |   0.128K               |   4.014M  |\n",
            "|    encoder.bn1.weight        |    (64,)               |           |\n",
            "|    encoder.bn1.bias          |    (64,)               |           |\n",
            "|   encoder.layer1             |   0.216M               |   0.69G   |\n",
            "|    encoder.layer1.0          |    75.008K             |    0.241G |\n",
            "|    encoder.layer1.1          |    70.4K               |    0.224G |\n",
            "|    encoder.layer1.2          |    70.4K               |    0.224G |\n",
            "|   encoder.layer2             |   1.22M                |   1.043G  |\n",
            "|    encoder.layer2.0          |    0.379M              |    0.379G |\n",
            "|    encoder.layer2.1          |    0.28M               |    0.221G |\n",
            "|    encoder.layer2.2          |    0.28M               |    0.221G |\n",
            "|    encoder.layer2.3          |    0.28M               |    0.221G |\n",
            "|   encoder.layer3             |   7.098M               |   1.475G  |\n",
            "|    encoder.layer3.0          |    1.512M              |    0.376G |\n",
            "|    encoder.layer3.1          |    1.117M              |    0.22G  |\n",
            "|    encoder.layer3.2          |    1.117M              |    0.22G  |\n",
            "|    encoder.layer3.3          |    1.117M              |    0.22G  |\n",
            "|    encoder.layer3.4          |    1.117M              |    0.22G  |\n",
            "|    encoder.layer3.5          |    1.117M              |    0.22G  |\n",
            "|   encoder.layer4             |   14.965M              |   0.812G  |\n",
            "|    encoder.layer4.0          |    6.04M               |    0.374G |\n",
            "|    encoder.layer4.1          |    4.463M              |    0.219G |\n",
            "|    encoder.layer4.2          |    4.463M              |    0.219G |\n",
            "|  decoder.blocks              |  9.013M                |  4.065G   |\n",
            "|   decoder.blocks.0           |   7.669M               |   1.504G  |\n",
            "|    decoder.blocks.0.conv1    |    7.078M              |    1.388G |\n",
            "|    decoder.blocks.0.conv2    |    0.59M               |    0.116G |\n",
            "|   decoder.blocks.1           |   1.033M               |   0.81G   |\n",
            "|    decoder.blocks.1.conv1    |    0.885M              |    0.694G |\n",
            "|    decoder.blocks.1.conv2    |    0.148M              |    0.116G |\n",
            "|   decoder.blocks.2           |   0.258M               |   0.812G  |\n",
            "|    decoder.blocks.2.conv1    |    0.221M              |    0.695G |\n",
            "|    decoder.blocks.2.conv2    |    36.992K             |    0.117G |\n",
            "|   decoder.blocks.3           |   46.208K              |   0.583G  |\n",
            "|    decoder.blocks.3.conv1    |    36.928K             |    0.464G |\n",
            "|    decoder.blocks.3.conv2    |    9.28K               |    0.118G |\n",
            "|   decoder.blocks.4           |   6.976K               |   0.356G  |\n",
            "|    decoder.blocks.4.conv1    |    4.64K               |    0.235G |\n",
            "|    decoder.blocks.4.conv2    |    2.336K              |    0.12G  |\n",
            "|  segmentation_head.0         |  0.145K                |  7.225M   |\n",
            "|   segmentation_head.0.weight |   (1, 16, 3, 3)        |           |\n",
            "|   segmentation_head.0.bias   |   (1,)                 |           |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(flop_count_table(flops_mobilenetv2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okGh-OKe8cKe",
        "outputId": "5a8f2e5e-2ace-476b-8810-50403bbd314c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| module                        | #parameters or shape   | #flops     |\n",
            "|:------------------------------|:-----------------------|:-----------|\n",
            "| model                         | 6.629M                 | 2.613G     |\n",
            "|  encoder.features             |  2.224M                |  0.333G    |\n",
            "|   encoder.features.0          |   0.928K               |   12.845M  |\n",
            "|    encoder.features.0.0       |    0.864K              |    10.838M |\n",
            "|    encoder.features.0.1       |    64                  |    2.007M  |\n",
            "|   encoder.features.1.conv     |   0.896K               |   13.046M  |\n",
            "|    encoder.features.1.conv.0  |    0.352K              |    5.62M   |\n",
            "|    encoder.features.1.conv.1  |    0.512K              |    6.423M  |\n",
            "|    encoder.features.1.conv.2  |    32                  |    1.004M  |\n",
            "|   encoder.features.2.conv     |   5.136K               |   37.105M  |\n",
            "|    encoder.features.2.conv.0  |    1.728K              |    25.289M |\n",
            "|    encoder.features.2.conv.1  |    1.056K              |    4.215M  |\n",
            "|    encoder.features.2.conv.2  |    2.304K              |    7.225M  |\n",
            "|    encoder.features.2.conv.3  |    48                  |    0.376M  |\n",
            "|   encoder.features.3.conv     |   8.832K               |   30.632M  |\n",
            "|    encoder.features.3.conv.0  |    3.744K              |    13.096M |\n",
            "|    encoder.features.3.conv.1  |    1.584K              |    6.322M  |\n",
            "|    encoder.features.3.conv.2  |    3.456K              |    10.838M |\n",
            "|    encoder.features.3.conv.3  |    48                  |    0.376M  |\n",
            "|   encoder.features.4.conv     |   10K                  |   18.415M  |\n",
            "|    encoder.features.4.conv.0  |    3.744K              |    13.096M |\n",
            "|    encoder.features.4.conv.1  |    1.584K              |    1.581M  |\n",
            "|    encoder.features.4.conv.2  |    4.608K              |    3.613M  |\n",
            "|    encoder.features.4.conv.3  |    64                  |    0.125M  |\n",
            "|   encoder.features.5.conv     |   14.848K              |   12.619M  |\n",
            "|    encoder.features.5.conv.0  |    6.528K              |    5.57M   |\n",
            "|    encoder.features.5.conv.1  |    2.112K              |    2.107M  |\n",
            "|    encoder.features.5.conv.2  |    6.144K              |    4.817M  |\n",
            "|    encoder.features.5.conv.3  |    64                  |    0.125M  |\n",
            "|   encoder.features.6.conv     |   14.848K              |   12.619M  |\n",
            "|    encoder.features.6.conv.0  |    6.528K              |    5.57M   |\n",
            "|    encoder.features.6.conv.1  |    2.112K              |    2.107M  |\n",
            "|    encoder.features.6.conv.2  |    6.144K              |    4.817M  |\n",
            "|    encoder.features.6.conv.3  |    64                  |    0.125M  |\n",
            "|   encoder.features.7.conv     |   21.056K              |   8.568M   |\n",
            "|    encoder.features.7.conv.0  |    6.528K              |    5.57M   |\n",
            "|    encoder.features.7.conv.1  |    2.112K              |    0.527M  |\n",
            "|    encoder.features.7.conv.2  |    12.288K             |    2.408M  |\n",
            "|    encoder.features.7.conv.3  |    0.128K              |    62.72K  |\n",
            "|   encoder.features.8.conv     |   54.272K              |   11.127M  |\n",
            "|    encoder.features.8.conv.0  |    25.344K             |    5.193M  |\n",
            "|    encoder.features.8.conv.1  |    4.224K              |    1.054M  |\n",
            "|    encoder.features.8.conv.2  |    24.576K             |    4.817M  |\n",
            "|    encoder.features.8.conv.3  |    0.128K              |    62.72K  |\n",
            "|   encoder.features.9.conv     |   54.272K              |   11.127M  |\n",
            "|    encoder.features.9.conv.0  |    25.344K             |    5.193M  |\n",
            "|    encoder.features.9.conv.1  |    4.224K              |    1.054M  |\n",
            "|    encoder.features.9.conv.2  |    24.576K             |    4.817M  |\n",
            "|    encoder.features.9.conv.3  |    0.128K              |    62.72K  |\n",
            "|   encoder.features.10.conv    |   54.272K              |   11.127M  |\n",
            "|    encoder.features.10.conv.0 |    25.344K             |    5.193M  |\n",
            "|    encoder.features.10.conv.1 |    4.224K              |    1.054M  |\n",
            "|    encoder.features.10.conv.2 |    24.576K             |    4.817M  |\n",
            "|    encoder.features.10.conv.3 |    0.128K              |    62.72K  |\n",
            "|   encoder.features.11.conv    |   66.624K              |   13.566M  |\n",
            "|    encoder.features.11.conv.0 |    25.344K             |    5.193M  |\n",
            "|    encoder.features.11.conv.1 |    4.224K              |    1.054M  |\n",
            "|    encoder.features.11.conv.2 |    36.864K             |    7.225M  |\n",
            "|    encoder.features.11.conv.3 |    0.192K              |    94.08K  |\n",
            "|   encoder.features.12.conv    |   0.118M               |   23.915M  |\n",
            "|    encoder.features.12.conv.0 |    56.448K             |    11.402M |\n",
            "|    encoder.features.12.conv.1 |    6.336K              |    1.581M  |\n",
            "|    encoder.features.12.conv.2 |    55.296K             |    10.838M |\n",
            "|    encoder.features.12.conv.3 |    0.192K              |    94.08K  |\n",
            "|   encoder.features.13.conv    |   0.118M               |   23.915M  |\n",
            "|    encoder.features.13.conv.0 |    56.448K             |    11.402M |\n",
            "|    encoder.features.13.conv.1 |    6.336K              |    1.581M  |\n",
            "|    encoder.features.13.conv.2 |    55.296K             |    10.838M |\n",
            "|    encoder.features.13.conv.3 |    0.192K              |    94.08K  |\n",
            "|   encoder.features.14.conv    |   0.155M               |   16.353M  |\n",
            "|    encoder.features.14.conv.0 |    56.448K             |    11.402M |\n",
            "|    encoder.features.14.conv.1 |    6.336K              |    0.395M  |\n",
            "|    encoder.features.14.conv.2 |    92.16K              |    4.516M  |\n",
            "|    encoder.features.14.conv.3 |    0.32K               |    39.2K   |\n",
            "|   encoder.features.15.conv    |   0.32M                |   15.986M  |\n",
            "|    encoder.features.15.conv.0 |    0.156M              |    7.762M  |\n",
            "|    encoder.features.15.conv.1 |    10.56K              |    0.659M  |\n",
            "|    encoder.features.15.conv.2 |    0.154M              |    7.526M  |\n",
            "|    encoder.features.15.conv.3 |    0.32K               |    39.2K   |\n",
            "|   encoder.features.16.conv    |   0.32M                |   15.986M  |\n",
            "|    encoder.features.16.conv.0 |    0.156M              |    7.762M  |\n",
            "|    encoder.features.16.conv.1 |    10.56K              |    0.659M  |\n",
            "|    encoder.features.16.conv.2 |    0.154M              |    7.526M  |\n",
            "|    encoder.features.16.conv.3 |    0.32K               |    39.2K   |\n",
            "|   encoder.features.17.conv    |   0.474M               |   23.551M  |\n",
            "|    encoder.features.17.conv.0 |    0.156M              |    7.762M  |\n",
            "|    encoder.features.17.conv.1 |    10.56K              |    0.659M  |\n",
            "|    encoder.features.17.conv.2 |    0.307M              |    15.053M |\n",
            "|    encoder.features.17.conv.3 |    0.64K               |    78.4K   |\n",
            "|   encoder.features.18         |   0.412M               |   20.384M  |\n",
            "|    encoder.features.18.0      |    0.41M               |    20.07M  |\n",
            "|    encoder.features.18.1      |    2.56K               |    0.314M  |\n",
            "|  decoder.blocks               |  4.405M                |  2.273G    |\n",
            "|   decoder.blocks.0            |   3.761M               |   0.738G   |\n",
            "|    decoder.blocks.0.conv1     |    3.171M              |    0.622G  |\n",
            "|    decoder.blocks.0.conv2     |    0.59M               |    0.116G  |\n",
            "|   decoder.blocks.1            |   0.48M                |   0.377G   |\n",
            "|    decoder.blocks.1.conv1     |    0.332M              |    0.261G  |\n",
            "|    decoder.blocks.1.conv2     |    0.148M              |    0.116G  |\n",
            "|   decoder.blocks.2            |   0.125M               |   0.393G   |\n",
            "|    decoder.blocks.2.conv1     |    87.68K              |    0.276G  |\n",
            "|    decoder.blocks.2.conv2     |    36.992K             |    0.117G  |\n",
            "|   decoder.blocks.3            |   32.384K              |   0.409G   |\n",
            "|    decoder.blocks.3.conv1     |    23.104K             |    0.291G  |\n",
            "|    decoder.blocks.3.conv2     |    9.28K               |    0.118G  |\n",
            "|   decoder.blocks.4            |   6.976K               |   0.356G   |\n",
            "|    decoder.blocks.4.conv1     |    4.64K               |    0.235G  |\n",
            "|    decoder.blocks.4.conv2     |    2.336K              |    0.12G   |\n",
            "|  segmentation_head.0          |  0.145K                |  7.225M    |\n",
            "|   segmentation_head.0.weight  |   (1, 16, 3, 3)        |            |\n",
            "|   segmentation_head.0.bias    |   (1,)                 |            |\n"
          ]
        }
      ]
    }
  ]
}